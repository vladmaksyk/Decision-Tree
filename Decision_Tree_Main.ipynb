{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "from statistics import median, mode\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrType(Enum):\n",
    "    cat = 0  # categorical (qualitative) attribute\n",
    "    num = 1  # numerical (quantitative) attribute\n",
    "    target = 2  # target label\n",
    "\n",
    "\n",
    "class NodeType(Enum):\n",
    "    root = 0\n",
    "    internal = 1\n",
    "    leaf = 2\n",
    "\n",
    "\n",
    "class SplitType(Enum):\n",
    "    bin = 0  # binary split\n",
    "    multi = 1  # multi-way split#\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = NodeType.leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute(object):\n",
    "    def __init__(self, label, type):\n",
    "        assert type in AttrType\n",
    "        self.label = label\n",
    "        self.type = type\n",
    "        self.stat = None  # holds mean for numerical and mode for categorical attributes\n",
    "        \n",
    "class Splitting(object):\n",
    "    def __init__(self, attr, infogain, split_type, cond, splits):\n",
    "        self.attr = attr  # attribute ID (index in ATTR)\n",
    "        self.infogain = infogain  # information gain if splitting is done on this attribute\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.cond = cond  # splitting condition, i.e., values on outgoing edges\n",
    "        self.splits = splits  # list of training records (IDs) for each slitting condition\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, id, type, parent_id, children=None, edge_value=None, val=None, split_type=None, split_cond=None,\n",
    "                 infogain=None):\n",
    "        self.id = id  # ID (same as the index in DT.model list)\n",
    "        self.type = type  # one of NodeType\n",
    "        self.parent_id = parent_id  # ID of parent node (None if root)\n",
    "        self.children = children  # list of IDs of child nodes\n",
    "        self.edge_value = edge_value  # the value of the incoming edge (only if not root node)\n",
    "        self.val = val  # if root or internal node: the attribute that is compared at that node; if leaf node: the target value\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.split_cond = split_cond  # splitting condition (median value for binary splits on numerical values; otherwise a list of categorical values (corresponding to child nodes))\n",
    "        self.infogain = infogain\n",
    "\n",
    "    def append_child(self, node_id):\n",
    "        self.children.append(node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILE = \"data/basketball.train.csv\"\n",
    "TEST_FILE = \"data/basketball.test.csv\"\n",
    "\n",
    "OUTPUT_FILE = \"data/basketball.result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTR = [Attribute(\"LOCATION\", AttrType.cat),Attribute(\"W\", AttrType.cat), Attribute(\"FINAL_MARGIN\", AttrType.num),\n",
    "        Attribute(\"SHOT_NUMBER\", AttrType.num),Attribute(\"PERIOD\", AttrType.cat),Attribute(\"GAME_CLOCK\", AttrType.num),\n",
    "        Attribute(\"SHOT_CLOCK\", AttrType.num),Attribute(\"DRIBBLES\", AttrType.num), Attribute(\"TOUCH_TIME\", AttrType.num),\n",
    "        Attribute(\"SHOT_DIST\", AttrType.num),Attribute(\"PTS_TYPE\", AttrType.cat),Attribute(\"CLOSE_DEF_DIST\", AttrType.num),\n",
    "        Attribute(\"Target\", AttrType.target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_TARGET = len(ATTR) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT(object):\n",
    "    def __init__(self):\n",
    "        self.data = None  # training data set (loaded into memory)\n",
    "        self.model = None  # decision tree model\n",
    "        self.default_class = None  # default target class\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(INFILE) as csvfile:\n",
    "            self.data = []\n",
    "            csvreader = csv.reader(csvfile, delimiter=',')\n",
    "            for row in csvreader:\n",
    "                rec = []\n",
    "                for i in range(len(ATTR)):\n",
    "                    val = row[i].strip()\n",
    "                    # convert numerical attributes\n",
    "                    if ATTR[i].type == AttrType.num:  # Note that this will break for \"?\" (missing attribute)\n",
    "                        val = float(val)\n",
    "                    rec.append(val)\n",
    "                self.data.append(rec)\n",
    "                # self.data.append([element.strip() for element in row])  # strip spaces\n",
    "    \n",
    "    def median(self,index):\n",
    "        return median([self.data[idx][index] for idx in range(len(self.data))])\n",
    "    \n",
    "    def entropy(self, records):\n",
    "        count = Counter([self.data[x][IDX_TARGET] for x in records]) # count the terget class in dictionary\n",
    "        return sum([(-freq / len(records)) * math.log(freq / len(records), 2) for freq in count.values()])\n",
    "    \n",
    "    # given a set of records decides on wich attribute to split based on the biggest infogain value.\n",
    "    def find_best_attr(self, attrs, records):\n",
    "\n",
    "        entropy_p = self.entropy(records)  # parent's entropy\n",
    "        splittings = []  # holds the splitting information for each attribute\n",
    "\n",
    "        for a in attrs:\n",
    "            assert ATTR[a].type in AttrType\n",
    "            splits = {}  # record IDs corresponding to each split\n",
    "\n",
    "            if ATTR[a].type == AttrType.target:  # skip target attribute\n",
    "                continue\n",
    "            \n",
    "            elif ATTR[a].type == AttrType.cat:  # categorical attribute\n",
    "                #print(\"Categorical Attribute\")\n",
    "                split_mode = SplitType.multi\n",
    "                split_cond = set([self.data[idx][a] for idx in range(len(self.data))])\n",
    "                for condition in split_cond:\n",
    "                    splits[condition] = [i for i in records if self.data[i][a] == condition ]\n",
    "\n",
    "            elif ATTR[a].type == AttrType.num:  # numerical attribute => binary split on median value\n",
    "                #print(\"Numerical Attribute\")\n",
    "                split_mode = SplitType.bin\n",
    "                split_cond = self.median(a)  # (i.e., if less or equal than this value)\n",
    "                splits[str(split_cond)+\"under\"] = [i for i in records if self.data[i][a] <= split_cond ]\n",
    "                splits[str(split_cond)+\"over\"] = [i for i in records if self.data[i][a] > split_cond ]\n",
    "            \n",
    "            #print(\"splits - >\", splits)\n",
    "\n",
    "            total = 0\n",
    "            for split in splits :\n",
    "                entropy_each = self.entropy(splits[split])\n",
    "                total +=  entropy_each*(len(splits[split])/len(records))\n",
    "                \n",
    "            infogain = entropy_p - total\n",
    "\n",
    "            splitting = Splitting(a, infogain, split_mode, split_cond, splits)\n",
    "            splittings.append(splitting)\n",
    "\n",
    "        # find best splitting\n",
    "        best_splitting = sorted(splittings, key=lambda x: x.infogain, reverse=True)[0]\n",
    "        return best_splitting\n",
    "                \n",
    "    # Adds a node to the decision tree.\n",
    "    def add_node(self, parent_id, node_type=NodeType.internal, edge_value=None, val=None, split_type=None,split_cond=None):\n",
    "        node_id = len(self.model)  # id of the newly assigned node\n",
    "        if not self.model:  # the tree is empty\n",
    "            node_type = NodeType.root\n",
    "\n",
    "        node = Node(node_id, node_type, parent_id, children=[], edge_value=edge_value, val=val, split_type=split_type,\n",
    "                    split_cond=split_cond)\n",
    "        self.model.append(node)\n",
    "\n",
    "        # add it as a child of the parent node if there is such\n",
    "        if parent_id is not None:\n",
    "            self.model[parent_id].append_child(node_id)\n",
    "        return node_id\n",
    "    \n",
    "    # returns a decision tree.\n",
    "    def id3(self, attrs, records, parent_id=None, value=None):\n",
    "        \n",
    "        # empty training set or empty set of attributes => create leaf node with default class\n",
    "        if not records or not attrs:\n",
    "            #print(\"empty training set\")\n",
    "            self.add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=self.default_class)\n",
    "            return #returns nothing and stops function\n",
    "        \n",
    "        \n",
    "        # if all records have the same target value => create leaf node with that target value\n",
    "        same = all(self.data[idx][IDX_TARGET] == self.data[records[0]][IDX_TARGET] for idx in records)\n",
    "        #print(\"same ->\", same)\n",
    "        if same:\n",
    "            target = self.data[records[0]][IDX_TARGET]\n",
    "            self.add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=target)\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # if amount of records is less than 10000\n",
    "        if len(records) < 20000 : \n",
    "            default_class = Counter([self.data[x][IDX_TARGET] for x in records]).most_common(1)[0][0]\n",
    "            self.add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=default_class)\n",
    "        \n",
    "            \n",
    "        # find the attribute with the largest gain\n",
    "        splitting = self.find_best_attr(attrs, records)\n",
    "        \n",
    "        # add node\n",
    "        node_id = self.add_node(parent_id, edge_value=value, val=splitting.attr, split_type=splitting.split_type,\n",
    "                                  split_cond=splitting.cond)\n",
    " \n",
    "        # TODO call tree construction recursively for each split\n",
    "        attrs.remove(splitting.attr)        \n",
    "        for branch in splitting.splits:\n",
    "            self.id3(attrs, splitting.splits[branch], node_id, ATTR[splitting.attr].label)\n",
    "        return\n",
    "        \n",
    "    \n",
    "    def build_model(self):\n",
    "        self.load_data()\n",
    "        self.model = []  # holds the decision tree model, represented as a list of nodes\n",
    "        self.default_class = Counter([x[IDX_TARGET] for x in self.data]).most_common(1)[0][0]\n",
    "        amount_of_records = len(self.data)\n",
    "        self.id3(set(range(len(ATTR) - 1)), list(range(amount_of_records)))\n",
    "        \n",
    "    def apply_model(self, record):\n",
    "        node = self.model[0]\n",
    "        while node.type != NodeType.leaf:\n",
    "            if ATTR[node.val].type == AttrType.cat : \n",
    "                node_index = node.children[list(node.split_cond).index(record[node.val])]\n",
    "            else :\n",
    "                \n",
    "                if float(record[node.val]) <= node.split_cond:\n",
    "                    node_index = node.children[0]\n",
    "                else :\n",
    "                    node_index = node.children[1]\n",
    "            node = self.model[node_index]\n",
    "        return node.val\n",
    "    \n",
    "    def create_output(self):\n",
    "        temp_list = []\n",
    "        with open(TEST_FILE) as f :\n",
    "            csvreader = csv.reader(f,delimiter=',')\n",
    "            cnt = 0\n",
    "            for row in csvreader :\n",
    "                cnt +=1\n",
    "                temp_list.append([cnt,self.apply_model(row)])\n",
    "        file = open(OUTPUT_FILE,\"w\")\n",
    "        file.write(\"Id,Target\\n\") \n",
    "        for row in temp_list:\n",
    "            file.write(\"%s,%s\\n\" % (row[0], row[1]))\n",
    "        file.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dt = DT()\n",
    "    dt.build_model()\n",
    "    dt.create_output()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Practice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if list is empty\n",
    "rec = [1,2,3,4]\n",
    "if not rec:\n",
    "    print(\"hala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default argument principle\n",
    "def macs(sulo, ahuto = 5):\n",
    "    return sulo + ahuto\n",
    "\n",
    "print(macs(4,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty return statement\n",
    "def testReturn(a,b):\n",
    "    if a>b:\n",
    "        return\n",
    "    print(a+b)\n",
    "\n",
    "print(testReturn(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enum class\n",
    "class Days(Enum):\n",
    "    Sun = 1\n",
    "    Mon = 2\n",
    "    Tue = 3\n",
    "    \n",
    "print (Days.Mon)\n",
    "print (repr(Days.Sun))\n",
    "print (type(Days.Mon))\n",
    "print (Days.Tue.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List comprehensions\n",
    "data = [[1,2,3,\"miss\"],[4,5,6,\"score\"],[7,8,9,\"score\"],[10,11,12,\"score\"]]\n",
    "records = [0,1,2,3]\n",
    "\n",
    "IDX_TARGT = 3\n",
    "count = Counter([data[x][IDX_TARGT] for x in records])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
